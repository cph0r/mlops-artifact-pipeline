name: Run Tests

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8, 3.9, '3.10']
        
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
        
    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-${{ matrix.python-version }}-
          
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov flake8 black
        
    - name: Lint with flake8
      run: |
        # Stop the build if there are Python syntax errors or undefined names
        flake8 src/ tests/ --count --select=E9,F63,F7,F82 --show-source --statistics
        # Exit-zero treats all errors as warnings
        flake8 src/ tests/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
        
    - name: Check code formatting with black
      run: |
        black --check src/ tests/
        
    - name: Create test directories
      run: |
        mkdir -p artifacts
        
    - name: Run unit tests with pytest
      run: |
        cd tests
        python -m pytest test_train.py -v --cov=../src --cov-report=xml --cov-report=term-missing
        
    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      with:
        file: ./tests/coverage.xml
        flags: unittests
        name: codecov-umbrella
        
    - name: Test configuration loading
      run: |
        python -c "
        import json
        import os
        
        # Test config file exists and is valid JSON
        config_path = 'config/config.json'
        assert os.path.exists(config_path), f'Config file not found: {config_path}'
        
        with open(config_path, 'r') as f:
            config = json.load(f)
        
        # Check required keys
        required_keys = ['data', 'model', 'training', 'artifacts']
        for key in required_keys:
            assert key in config, f'Missing required config key: {key}'
        
        # Check model hyperparameters
        model_config = config['model']
        required_params = ['C', 'solver', 'max_iter']
        for param in required_params:
            assert param in model_config, f'Missing required model parameter: {param}'
        
        print('âœ… Configuration validation passed!')
        "
        
    - name: Test model training functionality
      run: |
        cd src
        python -c "
        import sys
        import os
        sys.path.append(os.path.dirname(os.path.abspath('.')))
        
        # Test basic imports
        from train import train_model, evaluate_model, load_data, save_model
        from utils import setup_logging, load_config, save_artifacts
        
        print('âœ… All imports successful!')
        
        # Test data loading
        X, y = load_data()
        print(f'âœ… Data loaded: {X.shape[0]} samples, {X.shape[1]} features')
        
        # Test config loading
        config = load_config('../config/config.json')
        print(f'âœ… Config loaded with {len(config)} sections')
        "
        
    - name: Check for security vulnerabilities
      run: |
        pip install safety
        safety check
        
    - name: Create test summary
      run: |
        echo "## ðŸ§ª Test Summary" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "**Python Version:** ${{ matrix.python-version }}" >> $GITHUB_STEP_SUMMARY
        echo "**Status:** âœ… All tests passed" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "### Test Coverage" >> $GITHUB_STEP_SUMMARY
        echo "- Configuration loading: âœ…" >> $GITHUB_STEP_SUMMARY
        echo "- Model creation: âœ…" >> $GITHUB_STEP_SUMMARY
        echo "- Model accuracy validation: âœ…" >> $GITHUB_STEP_SUMMARY
        echo "- Data loading: âœ…" >> $GITHUB_STEP_SUMMARY
        echo "- Model saving: âœ…" >> $GITHUB_STEP_SUMMARY
        echo "- Integration tests: âœ…" >> $GITHUB_STEP_SUMMARY
        echo "- Code quality checks: âœ…" >> $GITHUB_STEP_SUMMARY
        echo "- Security checks: âœ…" >> $GITHUB_STEP_SUMMARY 